{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from math import pow, sqrt\n",
    "\n",
    "#Constant Values\n",
    "preprocessing = False\n",
    "calculateConstant_x = 300\n",
    "calculateConstant_y = 615\n",
    "personLabelID = 15.00\n",
    "debug = True\n",
    "accuracyThreshold = 0.4\n",
    "RED = (0,0,255)\n",
    "YELLOW = (0,255,255)\n",
    "GREEN = (0,255,0)\n",
    "write_video = False\n",
    "\n",
    "# I used CLAHE preprocessing algorithm for detect humans better.\n",
    "# HSV (Hue, Saturation, and Value channel). CLAHE uses value channel.\n",
    "# Value channel refers to the lightness or darkness of a colour. An image without hue or saturation is a grayscale image.\n",
    "def CLAHE(bgr_image: np.array) -> np.array:\n",
    "    hsv = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_planes = cv2.split(hsv)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    hsv_planes[2] = clahe.apply(hsv_planes[2])\n",
    "    hsv = cv2.merge(hsv_planes)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def centroid(startX,endX,startY,endY):\n",
    "    centroid_x = round((startX+endX)/2,4)\n",
    "    centroid_y = round((startY+endY)/2,4)\n",
    "    bboxHeight = round(endY-startY,4)\n",
    "    return centroid_x,centroid_y,bboxHeight\n",
    "\n",
    "def calcDistance(bboxHeight):\n",
    "    distance = (calculateConstant_x * calculateConstant_y) / bboxHeight\n",
    "    return distance\n",
    "\n",
    "def drawResult(frame,position):\n",
    "    for i in position.keys():\n",
    "        if i in highRisk:\n",
    "            rectangleColor = RED\n",
    "        elif i in mediumRisk:\n",
    "            rectangleColor = YELLOW\n",
    "        else:\n",
    "            rectangleColor = GREEN\n",
    "        (startX, startY, endX, endY) = detectionCoordinates[i]\n",
    "\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), rectangleColor, 2)\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "\n",
    "    caffeNetwork = cv2.dnn.readNetFromCaffe(\"C:/Users/HP/Desktop/tensorflow/Social_Distancing-CV-master/Social_Distancing-CV-master/SSD_MobileNet_prototxt.txt\", \"C:/Users/HP/Desktop/tensorflow/Social_Distancing-CV-master/Social_Distancing-CV-master/SSD_MobileNet.caffemodel\")\n",
    "    cap = cv2.VideoCapture(\"C:/Users/HP/Desktop/tensorflow/Social_Distancing-CV-master/Social_Distancing-CV-master/people.mp4\")\n",
    "    #fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    #output_movie = cv2.VideoWriter(\"./result.avi\", fourcc, 24, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        debug_frame, frame = cap.read()\n",
    "        highRisk = set()\n",
    "        mediumRisk = set()\n",
    "        position = dict()\n",
    "        detectionCoordinates = dict()\n",
    "\n",
    "        if not debug_frame:\n",
    "            print(\"Video cannot opened or finished!\")\n",
    "            break\n",
    "\n",
    "        if preprocessing:\n",
    "            frame = CLAHE(frame)\n",
    "\n",
    "        (imageHeight, imageWidth) = frame.shape[:2]\n",
    "        pDetection = cv2.dnn.blobFromImage(cv2.resize(frame, (imageWidth, imageHeight)), 0.007843, (imageWidth, imageHeight), 127.5)\n",
    "\n",
    "        caffeNetwork.setInput(pDetection)\n",
    "        detections = caffeNetwork.forward()\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "\n",
    "            accuracy = detections[0, 0, i, 2]\n",
    "            if accuracy > accuracyThreshold:\n",
    "                # Detection class and detection box coordinates.\n",
    "                idOfClasses = int(detections[0, 0, i, 1])\n",
    "                box = detections[0, 0, i, 3:7] * np.array([imageWidth, imageHeight, imageWidth, imageHeight])\n",
    "                (startX, startY, endX, endY) = box.astype('int')\n",
    "\n",
    "                if idOfClasses == personLabelID:\n",
    "                    # Default drawing bounding box.\n",
    "                    bboxDefaultColor = (255,255,255)\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), bboxDefaultColor, 2)\n",
    "                    detectionCoordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                    # Centroid of bounding boxes\n",
    "                    centroid_x, centroid_y, bboxHeight = centroid(startX,endX,startY,endY)                    \n",
    "                    distance = calcDistance(bboxHeight)\n",
    "                    # Centroid in centimeter distance\n",
    "                    centroid_x_centimeters = (centroid_x * distance) / calculateConstant_y\n",
    "                    centroid_y_centimeters = (centroid_y * distance) / calculateConstant_y\n",
    "                    position[i] = (centroid_x_centimeters, centroid_y_centimeters, distance)\n",
    "\n",
    "        #Risk Counter Using Distance of Positions\n",
    "        for i in position.keys():\n",
    "            for j in position.keys():\n",
    "                if i < j:\n",
    "                    distanceOfBboxes = sqrt(pow(position[i][0]-position[j][0],2) \n",
    "                                          + pow(position[i][1]-position[j][1],2) \n",
    "                                          + pow(position[i][2]-position[j][2],2)\n",
    "                                          )\n",
    "                    if distanceOfBboxes < 150: # 150cm or lower\n",
    "                        highRisk.add(i),highRisk.add(j)\n",
    "                    elif distanceOfBboxes < 200 > 150: # between 150 and 200\n",
    "                        mediumRisk.add(i),mediumRisk.add(j) \n",
    "       \n",
    "\n",
    "        cv2.putText(frame, \"Person in High Risk : \" + str(len(highRisk)) , (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Person in Medium Risk : \" + str(len(mediumRisk)) , (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Detected Person : \" + str(len(detectionCoordinates)), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        drawResult(frame, position)\n",
    "        if write_video:            \n",
    "            output_movie.write(frame)\n",
    "        cv2.imshow('Result', frame)\n",
    "        waitkey = cv2.waitKey(1)\n",
    "        if waitkey == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
